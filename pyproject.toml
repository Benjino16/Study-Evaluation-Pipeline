[build-system]
requires = ["setuptools>=68", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "study-evaluation-pipeline"
version = "0.2.0"
requires-python = ">=3.13"
dependencies = [
    "python-dotenv==1.1.1",
    "openai==2.5.0",
    "google-genai==1.45.0",
    "pypdf==6.1.2",
    "tabulate==0.9.0",
    "pyyaml==6.0.3",
    "pandas==2.3.3",
    "pandas-stubs==2.3.2.250926",
    "scikit-learn==1.7.2",
]

[project.optional-dependencies]
dev = ["pytest"]

[tool.setuptools]
package-dir = {"" = "src"}

[tool.setuptools.packages.find]
where = ["src"]

[project.scripts]
sep-run = "sep.paper2llm.cli:main"
sep-reconcile = "sep.reconciliation_manager:main"
sep-api-test = "sep.api_request.api_test:main"

sep-combine-csv-answers = "sep.evaluation.comebine_csv_answers:main"
sep-create-csv = "sep.evaluation.create_csv:main"
sep-edit-run-information = "sep.evaluation.edit_run_information:main"
sep-evaluate-reconciliation = "sep.evaluation.evaluate_reconciliation:main"
sep-export-results = "sep.evaluation.export_results_as_csv:main"
sep-set-attribute-of-run = "sep.evaluation.set_attribute_of_run:main"
sep-compare-answers = "sep.evaluation.compare_answers:main"
sep-evaluate-run = "sep.evaluation.evaluate_run:main"
sep-er = "sep.evaluation.evaluate_run:main"
sep-display-runs = "sep.display_runs:main"
sep-prompt-designer = "sep.prompt_designer.run_prompt_design:main"
